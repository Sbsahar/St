import os
import subprocess
import telebot
import whisper
from moviepy.editor import VideoFileClip, CompositeVideoClip, ImageClip
from deep_translator import GoogleTranslator
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import textwrap
import re
import gc
import time

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ø·ÙˆØ·
arabic_font_path = "NotoNaskhArabic-Regular.ttf"
latin_font_path = "DejaVuSans.ttf"

# Ù‚Ø§Ù…ÙˆØ³ Ù„ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_data_storage = {}

# Ø¯Ø§Ù„Ø© ØªØµØ­ÙŠØ­ Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø§Ù…ÙŠØ©
def correct_dialect(text):
    print(f"Correcting dialect for: {text}")
    corrections = {
        "ÙˆØ´": "Ø´Ùˆ",
        "Ù…ØªØ²ÙˆØ´": "Ù…ØªØ²ÙˆØ¬",
        "Ù‚Ø¯Ø§Ù…Ø©": "Ù‚Ø¯ÙŠ",
        "Ø¹Ø¯": "Ø¹Ù†Ø¯",
        "Ù…Ø±ØªÙŠ": "Ø²ÙˆØ¬ØªÙŠ",
        "Ø¨ØªØ³Ø£Ù„": "ØªØ³Ø£Ù„"
    }
    for wrong, correct in corrections.items():
        text = text.replace(wrong, correct)
    print(f"Corrected to: {text}")
    return text

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ±Ø¬Ù…Ø© (Ù…Ø®ØµØµØ© Ù„Ù„Ø£ØºØ§Ù†ÙŠ)
def improve_translation(text, is_song=True):
    print(f"Improving translation for: {text}")
    original = text
    
    # Ù‚ÙˆØ§Ø¹Ø¯ Ø¹Ø§Ù…Ø©
    text = text.replace("ØºÙ†ÙŠÙ†ÙŠ ØŒ Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ø¢Ù† ØŒ Ø£ØºÙ†ÙŠÙ†ÙŠ ØŒ ÙˆØ³Ø£Ù†Ø§Ù…", "ØºÙ†Ù‘ÙŠÙ†ÙŠ Ù„Ø£Ù†Ø§Ù…")
    text = text.replace("ÙŠØ¬Ø¨ Ø£Ù† Ø£ØºÙ†ÙŠÙ†ÙŠ ØŒ Ø£Ù†Ø§Ù… Ø§Ù„Ø¢Ù† ØŒ Ø§Ù„Ù†ÙˆÙ…", "ØºÙ†Ù‘ÙŠÙ†ÙŠ Ù„Ø£Ù‡Ø¯Ø£ ÙˆØ£Ù†Ø§Ù…")
    text = text.replace("Ø´ÙØªÙŠÙƒ ØªØªØ­Ø±Ùƒ ØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø³Ù…Ø§Ø¹ Ø´ÙŠØ¡", "Ø´ÙØªØ§Ùƒ ØªØªØ­Ø±ÙƒØ§Ù† ÙˆÙ„Ø§ Ø£Ø³Ù…Ø¹ Ø´ÙŠØ¦Ù‹Ø§")
    text = text.replace("Ù„Ù‚Ø¯ Ø£ØµØ¨Ø­Øª Ù…Ø§ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø­ØªØ¶Ø§Ù† Ø°Ø§ÙƒØ±ØªÙ†Ø§ Ø³ÙŠÙƒÙˆÙ† ØªÙ‡ÙˆÙŠØ¯ÙŠ", "Ø£ØµØ¨Ø­ØªÙ Ù…Ø§ Ù„Ø§ ØªØ³ØªØ·ÙŠØ¹ Ø§Ø­ØªØ¶Ø§Ù†Ù‡ØŒ Ø°ÙƒØ±ÙŠØ§ØªÙ†Ø§ ØªÙ‡ÙˆÙŠØ¯ØªÙŠ")

    # Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ø®ØµØµØ© Ù„Ù€ "Headlights" Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
    if is_song:
        text = text.replace("Ø² Ù„Ù†Ø§", "Ø£ÙˆÙ‡ØŒ Ø£ÙˆÙ‡ØŒ Ø³Ø£Ø³ØªØ®Ø¯Ù… ÙƒÙ„ Ù†Ø¨Ø¶Ø© Ù‚Ù„Ø¨")
        text = text.replace("Ø£Ù†Ø§ Ù‚Ø§Ø¯Ù… Ø¹Ù…ÙŠÙ‚ Ø¬Ø¯Ø§", "Ø£Ø±ÙƒØ¶ Ø¨Ø­Ø±ÙŠØ© ÙÙŠ Ø§Ù„Ø¸Ù„Ø§Ù…")
        text = text.replace("ÙƒÙ„Ù‡Ù… ÙÙˆÙ‚ Ø¸Ù„Ø§Ù„Ù‡Ù…", "ÙƒÙ„ Ø§Ù„Ø¸Ù„Ø§Ù„ Ø®Ù„ÙÙŠ")
        text = text.replace("Ø¹Ø´ Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹", "Ø¹Ø´Ù‡Ø§ Ø¨ÙƒÙ„ Ù‚ÙˆØªÙƒ")
        text = text.replace("Ø¹Ø´Ù†ÙŠ ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ", "Ø¹Ø´Ù‡Ø§ Ù…Ø¹ÙŠØŒ Ø­Ø¨ÙŠØ¨ÙŠ")
        text = text.replace("Runnin 'ØµØ­ÙŠØ­", "Ø£Ø±ÙƒØ¶ ÙÙŠ Ø§Ù„Ø£Ø¶ÙˆØ§Ø¡ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©")
        text = text.replace("ÙŠØ¬Ø¨ Ø£Ù† Ø£ØªØ°ÙˆÙ‚ ÙƒÙ„ Ù„ÙŠÙ„Ø© Ø³Ø¹ÙŠØ¯Ø©", "ÙŠØ¬Ø¨ Ø£Ù† Ø£Ø·Ø§Ø±Ø¯ ÙƒÙ„ Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø¬ÙŠØ¯")
        text = text.replace("Ø£Ù†Ø§ ÙÙŠ Ø§Ù„Ø³ÙŠØ¯Ø©", "Ø£Ù†Ø§ Ø£Ø±ÙƒØ¶ ÙÙŠ Ø§Ù„Ø¸Ù„Ø§Ù…")
        text = text.replace("Ø³Ø£Ù„Ø¹Ø¨Ù‡Ø§ Ø¹Ù„Ù‰ Ø­Ø¯ Ø³ÙˆØ§Ø¡", "Ø³Ø£Ù„Ø¹Ø¨Ù‡Ø§ Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠÙ†")
        text = text.replace("ÙˆÙƒÙ„ Ù…Ø§ Ø£Ù†Ø§ Ø¹Ù„ÙŠÙ‡ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ©", "ÙˆØ£Ù†Ø§ Ø£Ø­ØªØ³ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ©")
        text = text.replace("Ù„Ø§ ØªÙƒÙ† Ø£ØµØ¯Ù‚Ø§Ø¡ Ø®Ø¯Ø§Ø¹", "Ù„Ø§ ØªØ®Ø¯Ø¹ Ø§Ù„Ø£ØµØ¯Ù‚Ø§Ø¡")
        text = text.replace("ÙÙ‚Ø· Ø£ÙƒØ±Ù‡Ù†ÙŠ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ø·Ø±ÙŠÙ‚", "Ø®Ø°Ù†ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©")
        text = text.replace("ÙŠØ¹ÙŠØ´.", "Ø¹Ø´Ù‡Ø§ Ø¨ÙƒÙ„ Ù‚ÙˆØªÙƒ")
        text = text.replace("Ù„Ù‚Ø¯ ÙƒÙ†Øª Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡", "Ù„Ù‚Ø¯ ÙƒÙ†Øª Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚")
        text = text.replace("Ù„Ù‚Ø¯ ÙƒÙ†Øª Ø¹Ù„Ù‰", "Ø£Ù†Ø§ Ø£Ø±ÙƒØ¶ ÙÙŠ Ø§Ù„Ø£Ø¶ÙˆØ§Ø¡")
        text = text.replace("Ø£ÙˆÙ‡ Ø£ÙˆÙ‡ ØŒ ÙŠØ¬Ø¨ Ø£Ù† Ø£ØªØ°ÙˆÙ‚ ÙƒÙ„ Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø¬ÙŠØ¯", "Ø£ÙˆÙ‡ Ø£ÙˆÙ‡ØŒ ÙŠØ¬Ø¨ Ø£Ù† Ø£Ø·Ø§Ø±Ø¯ ÙƒÙ„ Ø§Ù„Ø¶ÙˆØ¡ Ø§Ù„Ø¬ÙŠØ¯")
        text = text.replace("Ø­Ø¨ÙŠØ¨ÙŠ Ø£Ù†Ø§ ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ù† Ø°Ù„Ùƒ", "Ø­Ø¨ÙŠØ¨ÙŠØŒ Ø£Ù†Ø§ ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ù† Ø§Ù„Ø£Ø¶ÙˆØ§Ø¡ Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©")
    
    print(f"Improved from: {original} to: {text}")
    return text

# Ø¯Ø§Ù„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ­Ø¬Ù… Ø§Ù„Ø®Ø· ÙˆØ§Ù„Ø§Ø±ØªÙØ§Ø¹ (Ù…Ø¹ Ø¸Ù„ Ø°Ù‡Ø¨ÙŠ Ø®ÙÙŠÙ Ø¬Ø¯Ù‹Ø§ ÙˆØ¸Ù‡ÙˆØ± ØªØ¯Ø±ÙŠØ¬ÙŠ ÙˆØ®Ù„ÙÙŠØ© Ø³ÙˆØ¯Ø§Ø¡ Ø´ÙØ§ÙØ©)
def create_text_clip_pil(text, fontsize, color, bg_color, max_width, start_time, end_time, position):
    print(f"Creating text clip for: {text} from {start_time}s to {end_time}s")
    
    try:
        arabic_font = ImageFont.truetype(arabic_font_path, fontsize)
        latin_font = ImageFont.truetype(latin_font_path, fontsize)
        print("Fonts loaded successfully!")
    except Exception as e:
        print(f"Error loading font: {e}")
        arabic_font = ImageFont.load_default()
        latin_font = ImageFont.load_default()

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ (Ø¹Ø±Ø¨ÙŠØ© ÙˆØ£Ø¬Ù†Ø¨ÙŠØ©)
    segments = re.split(r'([A-Za-z0-9\s]+)', text)
    text_parts = [(seg, latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font) for seg in segments if seg.strip()]
    text_parts.reverse()  # Ø¹ÙƒØ³ Ø§Ù„ØªØ±ØªÙŠØ¨ Ù„Ù„ÙƒØªØ§Ø¨Ø© Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±

    # Ù„Ù Ø§Ù„Ù†Øµ Ù„ÙŠÙ†Ø§Ø³Ø¨ Ø§Ù„Ø¹Ø±Ø¶ (ØªØ­Ø³ÙŠÙ† Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„)
    avg_char_width = fontsize * 0.5
    max_chars = int(max_width // avg_char_width)
    wrapped_text = textwrap.fill(text, width=max_chars)
    lines = wrapped_text.split("\n")
    print(f"Text wrapped into {len(lines)} lines")

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„ÙƒÙ„ Ø³Ø·Ø± Ù…Ø¹ Ø¶Ø¨Ø· Ø§Ù„Ø§Ø±ØªÙØ§Ø¹
    dummy_img = Image.new("RGBA", (100, 100), (0, 0, 0, 0))
    draw = ImageDraw.Draw(dummy_img)
    line_heights = []
    line_widths = []
    for line in lines:
        total_width = 0
        total_height = 0
        line_segments = re.split(r'([A-Za-z0-9\s]+)', line)
        for seg in line_segments:
            if seg.strip():
                font = latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font
                bbox = draw.textbbox((0, 0), seg, font=font)
                total_width += bbox[2] - bbox[0] + 5
                total_height = max(total_height, bbox[3] - bbox[1] + 5)
        line_widths.append(total_width - 5)
        line_heights.append(total_height)

    img_width = max(line_widths) + 20 if line_widths else 100
    img_height = sum(line_heights) + 15 * len(lines) if line_heights else 50
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Øµ Ù…Ø¹ Ø®Ù„ÙÙŠØ© Ø³ÙˆØ¯Ø§Ø¡ Ø´ÙØ§ÙØ© ÙˆØ¸Ù„ Ø°Ù‡Ø¨ÙŠ Ø®ÙÙŠÙ Ø¬Ø¯Ù‹Ø§
    img = Image.new("RGBA", (img_width, img_height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    current_h = 0

    for line_idx, (line, h) in enumerate(zip(lines, line_heights)):
        # Ø±Ø³Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡ Ø§Ù„Ø´ÙØ§ÙØ© Ù„Ù„Ø³Ø·Ø±
        left = 0
        right = img_width
        top = current_h - 5
        bottom = current_h + h + 15
        bg_fill = (0, 0, 0, 128)  # Ø£Ø³ÙˆØ¯ Ø´ÙØ§Ù (alpha=128 Ù„Ø´ÙØ§ÙÙŠØ© Ø¬Ø²Ø¦ÙŠØ©)
        draw.rectangle([left, top, right, bottom], fill=bg_fill)
        
        # Ø±Ø³Ù… Ø§Ù„Ù†Øµ
        line_segments = re.split(r'([A-Za-z0-9\s]+)', line)
        line_segments = [seg for seg in line_segments if seg.strip()]
        line_segments.reverse()
        line_width = line_widths[line_idx]
        current_x = img_width - line_width - 10
        for seg in line_segments:
            font = latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font
            bbox = draw.textbbox((0, 0), seg, font=font)
            shadow_color = "#FFD700"
            shadow_offset = 0.5
            draw.text((current_x + shadow_offset, current_h + shadow_offset), seg, font=font, fill=shadow_color)
            draw.text((current_x, current_h), seg, font=font, fill=color)
            current_x += (bbox[2] - bbox[0]) + 5
        current_h += h + 15

    img_array = np.array(img)
    clip_duration = end_time - start_time
    clip = ImageClip(img_array).set_duration(clip_duration)\
                               .set_start(start_time)\
                               .crossfadein(0.5)\
                               .set_position(position)\
                               .set_opacity(0.8)
    print(f"Text clip created successfully for segment {start_time}-{end_time}")
    return clip

# Ø¯Ø§Ù„Ø© Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
def add_subtitles(video_path, segments, is_translation=True):
    print(f"Starting subtitle addition for {len(segments)} segments")
    video_clip = VideoFileClip(video_path)
    print(f"Video clip loaded: {video_clip.w}x{video_clip.h}, duration: {video_clip.duration}s")
    clips = []
    
    for i, (start_time, end_time, text) in enumerate(segments):
        print(f"Processing subtitle {i+1}/{len(segments)}")
        text_clip = create_text_clip_pil(
            text,
            fontsize=24,
            color="white",
            bg_color="black",
            max_width=video_clip.w * 0.8,
            start_time=start_time,
            end_time=end_time,
            position=("center", "bottom")
        )
        clips.append(text_clip)

    final_clip = CompositeVideoClip([video_clip] + clips)
    output_path = video_path.replace(".mp4", "_with_subtitles.mp4")
    print(f"Writing final video to: {output_path}")
    start_time_write = time.time()
    final_clip.write_videofile(output_path, codec="libx264", audio_codec="aac", threads=4, verbose=False, logger=None)
    print(f"Video writing completed in {time.time() - start_time_write:.2f} seconds!")
    
    video_clip.close()
    final_clip.close()
    for clip in clips:
        clip.close()
    print("All clips closed successfully")
    
    return output_path

# ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
def enhance_audio(audio_path):
    print(f"Enhancing audio: {audio_path}")
    enhanced_audio_path = audio_path.replace(".wav", "_enhanced.wav")
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", audio_path, "-af", "volume=2.0,highpass=f=200,lowpass=f=3000,equalizer=f=1000:t=h:w=200:g=2", enhanced_audio_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        print(f"Audio enhanced successfully: {enhanced_audio_path}")
        return enhanced_audio_path
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode() if e.stderr else "Unknown ffmpeg error"
        print(f"Error enhancing audio: {error_msg}")
        return audio_path

# Ø§Ù„ØªÙˆÙƒÙ† Ù‡Ù†Ø§
TOKEN = "7696186741:AAEUTv2Ufb3_N_5bbpvQyVSVauLQaTtlFSU"
bot = telebot.TeleBot(TOKEN)

DOWNLOAD_FOLDER = "downloads"
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

print("Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper...")
start_load = time.time()
model = whisper.load_model("medium", device="cpu")
print(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Whisper Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ {time.time() - start_load:.2f} Ø«ÙˆØ§Ù†Ù!")
translator = GoogleTranslator(source="auto", target="ar")
print("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­!")

# Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨ÙŠØ©
@bot.message_handler(commands=['start'])
def send_welcome(message):
    print(f"User {message.from_user.id} started the bot")
    welcome_message = (
        "ğŸ¥ *Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ ÙÙŠ Ø¨ÙˆØª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø³Ø­Ø±ÙŠ* ğŸ¥\n\n"
        "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ø¬Ø¹Ù„ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§ØªÙƒ ØªØªØ­Ø¯Ø« Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© ğŸ˜\n"
        "ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ Ù‡Ùˆ Ø¥Ø±Ø³Ø§Ù„ ÙÙŠØ¯ÙŠÙˆ ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø£Ùˆ ØªØ±Ø¬Ù…ØªÙ‡ ÙˆØ¥Ø¶Ø§ÙØªÙ‡ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ù…ÙŠØ² Ù…Ø¹ ØªØ£Ø«ÙŠØ±Ø§Øª Ø¨ØµØ±ÙŠØ© Ø±Ø§Ø¦Ø¹Ø©.\n\n"
        "âœ¨ *Ù…Ù…ÙŠØ²Ø§ØªÙŠ*:\n"
        "- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©.\n"
        "- ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù† Ø£ÙŠ Ù„ØºØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.\n"
        "- Ù†ØµÙˆØµ Ø¨Ø¸Ù„Ø§Ù„ Ø°Ù‡Ø¨ÙŠØ© Ø®ÙÙŠÙØ© ÙˆØ¸Ù‡ÙˆØ± ØªØ¯Ø±ÙŠØ¬ÙŠ.\n\n"
        "ğŸš€ Ø¬Ø§Ù‡Ø²ØŸ Ø£Ø±Ø³Ù„ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø¢Ù† ÙˆØ¬Ø±Ø¨ Ø§Ù„Ø³Ø­Ø± Ø¨Ù†ÙØ³Ùƒ!"
    )
    bot.reply_to(message, welcome_message, parse_mode='Markdown')

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Ù…Ø¹ Ø®ÙŠØ§Ø± Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù…Ø©)
@bot.message_handler(content_types=['video'])
def handle_video(message):
    print(f"New video message from user {message.from_user.id}, file_id: {message.video.file_id}, duration: {message.video.duration}s")
    chat_id = message.chat.id
    user_id = message.from_user.id
    user_data = {'video_path': None, 'audio_path': None, 'segments': None, 'language': None}
    
    bot.send_message(chat_id, "ğŸ“¥ *Ø¬Ø§Ø±Ù ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ù„Ø­Ø¸Ù‡ ÙˆØ§Ø­Ø¯Ø©* â³", parse_mode='Markdown')
    
    file_info = bot.get_file(message.video.file_id)
    downloaded_file = bot.download_file(file_info.file_path)
    video_path = os.path.join(DOWNLOAD_FOLDER, f"{message.video.file_id}.mp4")
    
    with open(video_path, "wb") as new_file:
        new_file.write(downloaded_file)
    
    print(f"Video downloaded to: {video_path}")
    bot.send_message(chat_id, "ğŸ¥ *ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­ØŒ Ø¬Ø§Ø±Ù Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„ÙŠÙ‡* ğŸ‰", parse_mode='Markdown')
    
    audio_path = video_path.replace(".mp4", ".wav")
    try:
        print("Starting audio extraction with ffmpeg...")
        bot.send_message(chat_id, "ğŸ¤ *Ø¬Ø§Ø±Ù Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØªØŒ Ø§Ù†ØªØ¸Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹* ğŸ¶", parse_mode='Markdown')
        subprocess.run(
            ["ffmpeg", "-y", "-i", video_path, "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        print(f"Audio extracted successfully to: {audio_path}")
        bot.send_message(chat_id, "ğŸ¤ *ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­* âœ…", parse_mode='Markdown')
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode() if e.stderr else "Unknown ffmpeg error"
        print(f"FFmpeg error during audio extraction: {error_msg}")
        bot.send_message(chat_id, f"âŒ *Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØª: {error_msg}* ğŸ˜”", parse_mode='Markdown')
        return
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØª
    audio_path = enhance_audio(audio_path)
    
    bot.send_message(chat_id, "ğŸ“ *Ø¬Ø§Ø±Ù ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†ØµØŒ Ø£Ø¹Ù…Ù„ Ø¨Ø¬Ø¯* âœï¸", parse_mode='Markdown')
    try:
        print("Starting Whisper transcription...")
        start_transcribe = time.time()
        result = model.transcribe(
            audio_path,
            language=None,
            fp16=False,
            verbose=True,
            word_timestamps=False,
            condition_on_previous_text=False
        )
        transcribe_time = time.time() - start_transcribe
        detected_language = result.get("language", "unknown")
        segments = result["segments"]
        print(f"Transcription completed in {transcribe_time:.2f} seconds: {len(segments)} segments found, language: {detected_language}")
        if len(segments) == 0:
            print("No segments detected! Trying with Arabic language setting...")
            result = model.transcribe(
                audio_path,
                language="ar",
                fp16=False,
                verbose=True,
                word_timestamps=False,
                condition_on_previous_text=False
            )
            detected_language = "ar"
            segments = result["segments"]
            print(f"Retry transcription with Arabic: {len(segments)} segments found")
        
        # ØªØµØ­ÙŠØ­ Ø§Ù„Ù„Ù‡Ø¬Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯ÙˆÙ† ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ segments
        filtered_segments = []
        for segment in segments:
            # ØªØµØ­ÙŠØ­ Ø§Ù„Ù„Ù‡Ø¬Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            if detected_language == "ar":
                segment["text"] = correct_dialect(segment["text"])
            filtered_segments.append(segment)
        
        segments = filtered_segments
        print(f"Processed segments: {len(segments)} (no intro filtering)")
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
        user_data['video_path'] = video_path
        user_data['audio_path'] = audio_path
        user_data['segments'] = segments
        user_data['language'] = detected_language
        user_data_storage[(user_id, chat_id)] = user_data
        
        # Ø±Ø³Ø§Ù„Ø© ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        if detected_language == "ar":
            lang_message = "ğŸŒŸ *ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø¬Ø§Ø±Ù Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØµÙˆØµ Ù„Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ* ğŸ“"
        else:
            lang_message = f"ğŸŒ *ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ØºØ©: {detected_language}ØŒ Ø¬Ø§Ø±Ù ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©* âœ¨"
        bot.send_message(chat_id, lang_message, parse_mode='Markdown')
        
        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®ÙŠØ§Ø±
        markup = telebot.types.InlineKeyboardMarkup(row_width=1)
        btn_extract = telebot.types.InlineKeyboardButton("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ¯Ù…Ø¬Ù‡ Ù…Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ğŸ“", callback_data="extract")
        btn_translate = telebot.types.InlineKeyboardButton("ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¯Ù…Ø¬Ù‡Ø§ ğŸŒ", callback_data="translate")
        markup.add(btn_extract, btn_translate)
        bot.send_message(chat_id, f"âœ… *ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­ ({len(segments)} Ø¬Ø²Ø¡)!*\n\n*Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ØŸ*\n\nâš ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù„Ø¹Ø§Ù…ÙŠØ© (Ù…ØµØ±ÙŠ/Ø®Ù„ÙŠØ¬ÙŠ)ØŒ Ø§Ù„Ø¯Ù‚Ø© Ø¬ÙŠØ¯Ø© Ù„ÙƒÙ† Ù‚Ø¯ ØªÙƒÙˆÙ† Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„ÙØµØ­Ù‰.*", reply_markup=markup, parse_mode='Markdown')
        
    except Exception as e:
        print(f"Whisper transcription error: {str(e)}")
        bot.send_message(chat_id, f"âŒ *Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ: {str(e)}* ğŸ˜“\nØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù…Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø¢Ø®Ø±!", parse_mode='Markdown')
        return

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
@bot.callback_query_handler(func=lambda call: True)
def handle_callback(call):
    chat_id = call.message.chat.id
    user_id = call.from_user.id
    data = call.data
    
    user_data = user_data_storage.get((user_id, chat_id))
    if not user_data:
        bot.answer_callback_query(call.id, "âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ø£Ø¹Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
        return
    
    video_path = user_data['video_path']
    audio_path = user_data['audio_path']
    segments = user_data['segments']
    detected_language = user_data['language']
    
    try:
        if data == "extract":
            print("User chose extract Arabic text")
            bot.answer_callback_query(call.id, "Ø¬Ø§Ø±Ù Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
            extracted_segments = [(seg['start'], seg['end'], seg['text'].strip()) for seg in segments if seg['text'].strip()]
            final_video_path = add_subtitles(video_path, extracted_segments, is_translation=False)
            bot.send_message(chat_id, "âœ… *ØªÙ… Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­* ğŸ“\nØ¥Ù„ÙŠÙƒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£ØµÙ„ÙŠØ©!", parse_mode='Markdown')
            with open(final_video_path, "rb") as video_file:
                bot.send_video(chat_id, video_file, caption="ğŸ¥ Ø¥Ù„ÙŠÙƒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ˜Š", parse_mode='Markdown')
            print(f"Extracted video sent to user {chat_id}")
        
        elif data == "translate":
            print("User chose translation")
            bot.answer_callback_query(call.id, "Ø¬Ø§Ø±Ù Ø§Ù„ØªØ±Ø¬Ù…Ø©...")
            translated_segments = []
            for segment in segments:
                start_time = segment["start"]
                end_time = segment["end"]
                original_text = segment["text"].strip()
                if not original_text:
                    continue
                print(f"Segment - Original: {original_text} ({start_time}s - {end_time}s)")
                if detected_language == "ar":
                    translated_text = correct_dialect(original_text)
                else:
                    translated_text = translator.translate(original_text)
                    if translated_text:
                        translated_text = improve_translation(translated_text, is_song=True)
                    else:
                        print(f"Translation failed for segment: {original_text}")
                        continue
                print(f"Translated: {translated_text}")
                translated_segments.append((start_time, end_time, translated_text))
            
            if not translated_segments:
                bot.send_message(chat_id, "âŒ *Ø¹Ø°Ø±Ø§Ù‹ØŒ ÙØ´Ù„Øª Ø§Ù„ØªØ±Ø¬Ù…Ø©* ğŸ˜¢\nØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù…Ø¹ ÙÙŠØ¯ÙŠÙˆ Ø¢Ø®Ø±!", parse_mode='Markdown')
                return
            
            final_video_path = add_subtitles(video_path, translated_segments, is_translation=True)
            bot.send_message(chat_id, "âœ… *ØªÙ… Ø¯Ù…Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­* ğŸŒ\nØ¥Ù„ÙŠÙƒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©!", parse_mode='Markdown')
            with open(final_video_path, "rb") as video_file:
                bot.send_video(chat_id, video_file, caption="ğŸ¥ Ø¥Ù„ÙŠÙƒ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ˜Š", parse_mode='Markdown')
            print(f"Translated video sent to user {chat_id}")
    
    except Exception as e:
        print(f"Error during subtitle integration: {str(e)}")
        bot.send_message(chat_id, f"âŒ *Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¯Ù…Ø¬ Ø§Ù„Ù†Øµ/Ø§Ù„ØªØ±Ø¬Ù…Ø©: {str(e)}* ğŸ˜¢\nØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰!", parse_mode='Markdown')
    
    finally:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        user_data_storage.pop((user_id, chat_id), None)
        print("Starting cleanup...")
        if os.path.exists(video_path):
            os.remove(video_path)
            print(f"Removed: {video_path}")
        if os.path.exists(audio_path):
            os.remove(audio_path)
            print(f"Removed: {audio_path}")
        if 'final_video_path' in locals() and os.path.exists(final_video_path):
            os.remove(final_video_path)
            print(f"Removed: {final_video_path}")
        gc.collect()
        print("Cleanup completed and GC run")

@bot.message_handler(content_types=['text'])
def handle_text(message):
    print(f"Text message from user {message.from_user.id}: {message.text}")
    bot.reply_to(message, "ğŸ¤” *Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø£Ù†Ø§ Ø¨ÙˆØª ØªØ±Ø¬Ù…Ø© ÙÙŠØ¯ÙŠÙˆ Ø§Ø­ØªØ±Ø§ÙÙŠ!* Ø£Ø±Ø³Ù„ ÙÙŠØ¯ÙŠÙˆ ÙˆØ³Ø£Ø¹Ø§Ù„Ø¬Ù‡ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø³Ø­Ø±ÙŠ âœ¨", parse_mode='Markdown')

print("Bot started and polling...")
bot.polling()
