import os
import subprocess
import telebot
import whisper
from moviepy.editor import VideoFileClip, CompositeVideoClip, ImageClip
from deep_translator import GoogleTranslator
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import textwrap
import re
import gc
import time

# تحديد الخطوط
arabic_font_path = "NotoNaskhArabic-Regular.ttf"
latin_font_path = "DejaVuSans.ttf"

# دالة لتحسين الترجمة (مخصصة للأغاني)
def improve_translation(text, is_song=True):
    print(f"Improving translation for: {text}")
    original = text
    
    # قواعد عامة
    text = text.replace("غنيني ، النوم الآن ، أغنيني ، وسأنام", "غنّيني لأنام")
    text = text.replace("يجب أن أغنيني ، أنام الآن ، النوم", "غنّيني لأهدأ وأنام")
    text = text.replace("شفتيك تتحرك ، يمكنني سماع شيء", "شفتاك تتحركان ولا أسمع شيئًا")
    text = text.replace("لقد أصبحت ما لا يمكنك احتضان ذاكرتنا سيكون تهويدي", "أصبحتُ ما لا تستطيع احتضانه، ذكرياتنا تهويدتي")

    # قواعد مخصصة لـ "Headlights" بناءً على الكلمات الدقيقة
    if is_song:
        text = text.replace("ز لنا", "أوه، أوه، سأستخدم كل نبضة قلب")
        text = text.replace("أنا قادم عميق جدا", "أركض بحرية في الظلام")
        text = text.replace("كلهم فوق ظلالهم", "كل الظلال خلفي")
        text = text.replace("عش حول هذا الموضوع", "عشها بكل قوتك")
        text = text.replace("عشني يا حبيبي", "عشها معي، حبيبي")
        text = text.replace("Runnin 'صحيح", "أركض في الأضواء الأمامية")
        text = text.replace("يجب أن أتذوق كل ليلة سعيدة", "يجب أن أطارد كل الضوء الجيد")
        text = text.replace("أنا في السيدة", "أنا أركض في الظلام")
        text = text.replace("سألعبها على حد سواء", "سألعبها من كلا الجانبين")
        text = text.replace("وكل ما أنا عليه على الحافة", "وأنا أحتسي على الحافة")
        text = text.replace("لا تكن أصدقاء خداع", "لا تخدع الأصدقاء")
        text = text.replace("فقط أكرهني على طول الطريق", "خذني إلى النهاية")
        text = text.replace("يعيش.", "عشها بكل قوتك")
        text = text.replace("لقد كنت على نفس الشيء", "لقد كنت على نفس الطريق")
        text = text.replace("لقد كنت على", "أنا أركض في الأضواء")
        text = text.replace("أوه أوه ، يجب أن أتذوق كل الضوء الجيد", "أوه أوه، يجب أن أطارد كل الضوء الجيد")
        text = text.replace("حبيبي أنا كل شيء عن ذلك", "حبيبي، أنا كل شيء عن الأضواء الأمامية")
    
    print(f"Improved from: {original} to: {text}")
    return text

# دالة إنشاء النص مع ضبط المسافات وحجم الخط والارتفاع (مع ظل ذهبي خفيف جدًا وظهور تدريجي)
def create_text_clip_pil(text, fontsize, color, bg_color, max_width, start_time, end_time, position):
    print(f"Creating text clip for: {text} from {start_time}s to {end_time}s")
    
    try:
        arabic_font = ImageFont.truetype(arabic_font_path, fontsize)
        latin_font = ImageFont.truetype(latin_font_path, fontsize)
        print("Fonts loaded successfully!")
    except Exception as e:
        print(f"Error loading font: {e}")
        arabic_font = ImageFont.load_default()
        latin_font = ImageFont.load_default()

    # تقسيم النص إلى أجزاء (عربية وأجنبية)
    segments = re.split(r'([A-Za-z0-9\s]+)', text)
    text_parts = [(seg, latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font) for seg in segments if seg.strip()]
    text_parts.reverse()  # عكس الترتيب للكتابة من اليمين إلى اليسار

    # لف النص ليناسب العرض (تحسين لتجنب التداخل)
    avg_char_width = fontsize * 0.5  # تقليل avg_char_width للسماح بنص أطول في سطر واحد
    max_chars = int(max_width // avg_char_width)
    wrapped_text = textwrap.fill(text, width=max_chars)
    lines = wrapped_text.split("\n")
    print(f"Text wrapped into {len(lines)} lines")

    # حساب الأبعاد لكل سطر مع ضبط الارتفاع
    dummy_img = Image.new("RGBA", (100, 100), (0, 0, 0, 0))
    draw = ImageDraw.Draw(dummy_img)
    line_heights = []
    line_widths = []
    for line in lines:
        total_width = 0
        total_height = 0
        line_segments = re.split(r'([A-Za-z0-9\s]+)', line)
        for seg in line_segments:
            if seg.strip():
                font = latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font
                bbox = draw.textbbox((0, 0), seg, font=font)
                total_width += bbox[2] - bbox[0] + 5  # إضافة مسافة 5 بكسل بين الأجزاء
                total_height = max(total_height, bbox[3] - bbox[1] + 5)  # زيادة الارتفاع للنصوص العربية
        line_widths.append(total_width - 5)  # تصحيح العرض بإزالة المسافة الأخيرة
        line_heights.append(total_height)

    img_width = max(line_widths) + 20
    img_height = sum(line_heights) + 15 * len(lines)  # زيادة المسافة بين السطور
    
    # رسم النص مع ظل ذهبي خفيف جدًا
    img = Image.new("RGBA", (img_width, img_height), (0, 0, 0, 0))  # خلفية شفافة
    draw = ImageDraw.Draw(img)
    current_h = 0

    for line, h in zip(lines, line_heights):
        line_segments = re.split(r'([A-Za-z0-9\s]+)', line)
        line_segments = [seg for seg in line_segments if seg.strip()]
        line_segments.reverse()  # عكس ترتيب الأجزاء في السطر
        current_x = img_width - line_widths[lines.index(line)] - 10  # بدء من اليمين
        for seg in line_segments:
            font = latin_font if re.match(r'[A-Za-z0-9\s]+', seg) else arabic_font
            bbox = draw.textbbox((0, 0), seg, font=font)
            # طبقة واحدة: ظل ذهبي خفيف
            shadow_color = "#FFD700"  # ذهبي قياسي
            shadow_offset = 0.5  # مسافة صغيرة جدًا للتوهج
            draw.text((current_x + shadow_offset, current_h + shadow_offset), seg, font=font, fill=shadow_color)
            # النص الرئيسي (أبيض)
            draw.text((current_x, current_h), seg, font=font, fill=color)
            current_x += (bbox[2] - bbox[0]) + 5  # إضافة مسافة بين الكلمات
        current_h += h + 15  # زيادة المسافة بين السطور

    img_array = np.array(img)
    clip_duration = end_time - start_time
    clip = ImageClip(img_array).set_duration(clip_duration)\
                               .set_start(start_time)\
                               .crossfadein(0.5)\
                               .set_position(position)\
                               .set_opacity(0.8)  # تأثير الظهور التدريجي (0.5 ثانية)
    print(f"Text clip created successfully for segment {start_time}-{end_time}")
    return clip

# دالة إضافة الترجمة إلى الفيديو
def add_subtitles(video_path, segments, is_translation=True):
    print(f"Starting subtitle addition for {len(segments)} segments")
    video_clip = VideoFileClip(video_path)
    print(f"Video clip loaded: {video_clip.w}x{video_clip.h}, duration: {video_clip.duration}s")
    clips = []
    
    for i, (start_time, end_time, text) in enumerate(segments):
        print(f"Processing subtitle {i+1}/{len(segments)}")
        text_clip = create_text_clip_pil(
            text,
            fontsize=24,  # حجم صغير للستوري
            color="white",
            bg_color="gray",
            max_width=video_clip.w * 0.8,  # عرض أكبر لسطر واحد
            start_time=start_time,
            end_time=end_time,
            position=("center", "bottom")
        )
        clips.append(text_clip)

    final_clip = CompositeVideoClip([video_clip] + clips)
    output_path = video_path.replace(".mp4", "_with_subtitles.mp4")
    print(f"Writing final video to: {output_path}")
    start_time_write = time.time()
    final_clip.write_videofile(output_path, codec="libx264", audio_codec="aac", threads=4, verbose=False, logger=None)
    print(f"Video writing completed in {time.time() - start_time_write:.2f} seconds!")
    
    video_clip.close()
    final_clip.close()
    for clip in clips:
        clip.close()
    print("All clips closed successfully")
    
    return output_path

# تحسين جودة الصوت
def enhance_audio(audio_path):
    print(f"Enhancing audio: {audio_path}")
    enhanced_audio_path = audio_path.replace(".wav", "_enhanced.wav")
    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", audio_path, "-af", "volume=2.0,highpass=f=200,lowpass=f=3000,equalizer=f=1000:t=h:w=200:g=2", enhanced_audio_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        print(f"Audio enhanced successfully: {enhanced_audio_path}")
        return enhanced_audio_path
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode() if e.stderr else "Unknown ffmpeg error"
        print(f"Error enhancing audio: {error_msg}")
        return audio_path

# التوكن هنا
TOKEN = "7696186741:AAEUTv2Ufb3_N_5bbpvQyVSVauLQaTtlFSU"
bot = telebot.TeleBot(TOKEN)

DOWNLOAD_FOLDER = "downloads"
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

print("جارٍ تحميل نموذج Whisper...")
start_load = time.time()
model = whisper.load_model("medium", device="cpu")
print(f"تم تحميل نموذج Whisper بنجاح في {time.time() - start_load:.2f} ثوانٍ!")
translator = GoogleTranslator(source="auto", target="ar")
print("تم تحميل نموذج الترجمة بنجاح!")

# رسالة ترحيبية
@bot.message_handler(commands=['start'])
def send_welcome(message):
    print(f"User {message.from_user.id} started the bot")
    welcome_message = (
        "🎥 *مرحبًا بك في بوت الترجمة السحري* 🎥\n\n"
        "أنا هنا لأجعل فيديوهاتك تتحدث بالعربية 😍\n"
        "كل ما عليك هو إرسال فيديو وسأقوم باستخراج النص أو ترجمته وإضافة النصوص إليه بطريقة احترافية.\n\n"
        "✨ *كيف تستخدمني؟*\n"
        "- أرسل أي فيديو تريد معالجته.\n"
        "- اختر: استخراج النص العربي أو ترجمته إلى العربية.\n\n"
        "جاهز؟ أرسل لي فيديو الآن 🚀"
    )
    bot.reply_to(message, welcome_message, parse_mode='Markdown')

# معالجة الفيديو (مع خيار الاستخراج أو الترجمة)
@bot.message_handler(content_types=['video'])
def handle_video(message):
    print(f"New video message from user {message.from_user.id}, file_id: {message.video.file_id}, duration: {message.video.duration}s")
    chat_id = message.chat.id
    user_data = {'video_path': None, 'audio_path': None, 'segments': None}
    
    bot.send_message(chat_id, "📥 *جارٍ تحميل الفيديو الخاص بك لحظه فقط* ⏳", parse_mode='Markdown')
    
    file_info = bot.get_file(message.video.file_id)
    downloaded_file = bot.download_file(file_info.file_path)
    video_path = os.path.join(DOWNLOAD_FOLDER, f"{message.video.file_id}.mp4")
    
    with open(video_path, "wb") as new_file:
        new_file.write(downloaded_file)
    
    print(f"Video downloaded to: {video_path}")
    bot.send_message(chat_id, "🎥 *تم تحميل الفيديو بنجاح جارٍ العمل عليه* 🎉", parse_mode='Markdown')
    
    audio_path = video_path.replace(".mp4", ".wav")
    try:
        print("Starting audio extraction with ffmpeg...")
        bot.send_message(chat_id, "🎤 *جارٍ استخراج الصوت انتظرني قليلا* 🎶", parse_mode='Markdown')
        subprocess.run(
            ["ffmpeg", "-y", "-i", video_path, "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            check=True
        )
        print(f"Audio extracted successfully to: {audio_path}")
        bot.send_message(chat_id, "🎤 *تم استخراج الصوت بنجاح* ✅", parse_mode='Markdown')
    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode() if e.stderr else "Unknown ffmpeg error"
        print(f"FFmpeg error during audio extraction: {error_msg}")
        bot.send_message(chat_id, f"❌ *عذرا حدث خطأ أثناء استخراج الصوت: {error_msg}* 😔", parse_mode='Markdown')
        return
    
    # تحسين الصوت
    audio_path = enhance_audio(audio_path)
    
    bot.send_message(chat_id, "📝 *جارٍ تحويل الصوت إلى نص أنا أعمل عليه* ✍️", parse_mode='Markdown')
    try:
        print("Starting Whisper transcription...")
        start_transcribe = time.time()
        result = model.transcribe(
            audio_path,
            language=None,  # الكشف التلقائي عن اللغة
            fp16=False,
            verbose=True,
            word_timestamps=False,
            condition_on_previous_text=False
        )
        transcribe_time = time.time() - start_transcribe
        segments = result["segments"]
        print(f"Transcription completed in {transcribe_time:.2f} seconds: {len(segments)} segments found")
        if len(segments) == 0:
            print("No segments detected! Trying with Arabic language setting...")
            result = model.transcribe(
                audio_path,
                language="ar",  # محاولة ثانية بالعربية
                fp16=False,
                verbose=True,
                word_timestamps=False,
                condition_on_previous_text=False
            )
            segments = result["segments"]
            print(f"Retry transcription with Arabic: {len(segments)} segments found")
        
        # فلترة الترجمة في البداية: تجاهل الـ segments القصيرة في أول 5 ثوانٍ (للموسيقى)
        filtered_segments = []
        for segment in segments:
            if segment["start"] < 5.0:  # أول 5 ثوانٍ
                word_count = len(segment["text"].strip().split())
                if word_count < 3:  # إذا كانت الجملة قصيرة (موسيقى أو صمت)، تجاهلها
                    print(f"Ignoring short segment in intro: {segment['text']} ({segment['start']}s)")
                    continue
            filtered_segments.append(segment)
        
        segments = filtered_segments
        print(f"Filtered segments: {len(segments)} (ignored intro music)")
        
        # حفظ البيانات للمستخدم
        user_data['video_path'] = video_path
        user_data['audio_path'] = audio_path
        user_data['segments'] = segments
        bot.set_data(message.from_user.id, user_data)
        
        # رسالة الخيار
        markup = telebot.types.InlineKeyboardMarkup(row_width=1)
        btn_extract = telebot.types.InlineKeyboardButton("استخراج النص العربي ودمجه مع الفيديو 📝", callback_data="extract")
        btn_translate = telebot.types.InlineKeyboardButton("ترجمة الفيديو للعربية ودمجها 🌐", callback_data="translate")
        markup.add(btn_extract, btn_translate)
        bot.send_message(chat_id, f"✅ *تم استخراج النص بنجاح ({len(segments)} جزء)!*\n\n*ماذا تريد؟*\n\n⚠️ *ملاحظة: للعامية (مصري/خليجي)، الدقة جيدة لكن قد تكون أقل من الفصحى.*", reply_markup=markup, parse_mode='Markdown')
        
    except Exception as e:
        print(f"Whisper transcription error: {str(e)}")
        bot.send_message(chat_id, f"❌ *عذرا حدث خطأ أثناء تحويل الصوت إلى نص: {str(e)}* 😓", parse_mode='Markdown')
        return

# معالجة الخيارات
@bot.callback_query_handler(func=lambda call: True)
def handle_callback(call):
    chat_id = call.message.chat.id
    user_id = call.from_user.id
    data = call.data
    
    user_data = bot.get_data(user_id)
    if not user_data:
        bot.answer_callback_query(call.id, "❌ خطأ في البيانات. أعد إرسال الفيديو.")
        return
    
    video_path = user_data['video_path']
    audio_path = user_data['audio_path']
    segments = user_data['segments']
    
    try:
        if data == "extract":
            print("User chose extract Arabic text")
            bot.answer_callback_query(call.id, "جارٍ دمج النص العربي...")
            # استخراج: استخدم النص الأصلي كـ subtitles
            extracted_segments = [(seg['start'], seg['end'], seg['text'].strip()) for seg in segments if seg['text'].strip()]
            final_video_path = add_subtitles(video_path, extracted_segments, is_translation=False)
            bot.send_message(chat_id, "✅ *تم دمج النص العربي بنجاح* 📝", parse_mode='Markdown')
            with open(final_video_path, "rb") as video_file:
                bot.send_video(chat_id, video_file, caption="إليك الفيديو مع النص العربي 😊", parse_mode='Markdown')
            print(f"Extracted video sent to user {chat_id}")
        
        elif data == "translate":
            print("User chose translation")
            bot.answer_callback_query(call.id, "جارٍ الترجمة...")
            # ترجمة: كما هو حاليًا
            translated_segments = []
            for segment in segments:
                start_time = segment["start"]
                end_time = segment["end"]
                original_text = segment["text"].strip()
                if not original_text:
                    continue
                print(f"Segment - Original: {original_text} ({start_time}s - {end_time}s)")
                translated_text = translator.translate(original_text)
                if translated_text:
                    translated_text = improve_translation(translated_text, is_song=True)
                    print(f"Translated: {translated_text}")
                    translated_segments.append((start_time, end_time, translated_text))
                else:
                    print(f"Translation failed for segment")
            
            if not translated_segments:
                bot.send_message(chat_id, "❌ *عذرا، فشلت الترجمة* 😢", parse_mode='Markdown')
                return
            
            final_video_path = add_subtitles(video_path, translated_segments, is_translation=True)
            bot.send_message(chat_id, "✅ *تم دمج الترجمة بنجاح* 🌐", parse_mode='Markdown')
            with open(final_video_path, "rb") as video_file:
                bot.send_video(chat_id, video_file, caption="إليك الفيديو المترجم 😊", parse_mode='Markdown')
            print(f"Translated video sent to user {chat_id}")
    
    except Exception as e:
        print(f"Error during subtitle integration: {str(e)}")
        bot.send_message(chat_id, f"❌ *عذرا حدث خطأ أثناء دمج النص/الترجمة: {str(e)}* 😢", parse_mode='Markdown')
    
    finally:
        # تنظيف البيانات
        bot.delete_state(user_id, chat_id)
        bot.delete_data(user_id)
        print("Starting cleanup...")
        if os.path.exists(video_path):
            os.remove(video_path)
            print(f"Removed: {video_path}")
        if os.path.exists(audio_path):
            os.remove(audio_path)
            print(f"Removed: {audio_path}")
        if 'final_video_path' in locals() and os.path.exists(final_video_path):
            os.remove(final_video_path)
            print(f"Removed: {final_video_path}")
        gc.collect()
        print("Cleanup completed and GC run")

@bot.message_handler(content_types=['text'])
def handle_text(message):
    print(f"Text message from user {message.from_user.id}: {message.text}")
    bot.reply_to(message, "🤔 *عذرا أنا بوت ترجمة فيديو فقط* أرسل لي فيديو ودعني أترجمه إلى العربية ✨", parse_mode='Markdown')

print("Bot started and polling...")
bot.polling()
